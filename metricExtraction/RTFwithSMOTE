import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score, roc_curve, precision_recall_curve
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt

# === Charger ton CSV ===
df = pd.read_csv("metricExtraction/pet_features.csv")
X = df.drop(columns=["label"])
y = df["label"]

from sklearn.impute import SimpleImputer
import numpy as np


# === Split stratifié (préserve proportions) ===
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

imputer = SimpleImputer(strategy="mean")  # ou "median" / "most_frequent"
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# === Rééquilibrage avec SMOTE sur le train uniquement ===
sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X_train_imputed, y_train)

print(f"Taille avant SMOTE: {X_train.shape}, après SMOTE: {X_res.shape}")

# === Entraînement ===
rf = RandomForestClassifier(random_state=42)
rf.fit(X_res, y_res)

# === Prédictions probabilistes ===
y_proba = rf.predict_proba(X_test_imputed)[:, 1]

# === Test de plusieurs seuils ===
thresholds = [0.5, 0.4, 0.3, 0.2]
for t in thresholds:
    y_pred = (y_proba > t).astype(int)
    print(f"\n=== Threshold {t} ===")
    print(classification_report(y_test, y_pred, digits=3))

# === Courbe ROC ===
fpr, tpr, _ = roc_curve(y_test, y_proba)
plt.plot(fpr, tpr, label=f"AUC={roc_auc_score(y_test, y_proba):.3f}")
plt.plot([0,1],[0,1],'--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.title("ROC Curve")
plt.show()

# === Courbe Precision-Recall ===
prec, rec, thr = precision_recall_curve(y_test, y_proba)
plt.plot(rec, prec, label="PR curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.show()
